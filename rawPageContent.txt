what this is for - This tool is only for analysis of quality of a gpx and inturn the device that was used for it. this doesnt give a score for it this doesnt give predicitons or derive conclusions, but lets u drive ur own conclusions. this is for observation only and no repurposing
constraints - best usecase for raw gpx files, not merged and not pre-processed. they wud introduce invariants that this system does not account for and will only after studying bad gpx data from x reasons like export fault, faulty merging, pre-processed gpx trends etc.

the system will tell about most relevant data there is in the gpx file, like total number of points found etc. only raise flags as counters about what is objectively wrong in the gpx such as point to point comparison backtrack of time or equal timestamps, how many points were discarded because of x reason.
that is another constraint, sometimes during export or writing of gpx file, there can be mismatch of timestamps or ordering or even mislogging of the timestamp during activity. big segments of a gpx being timestamped is something that has not been observed by me yet in a raw gpx. it usually occurs in merged files that were combined in incorrect order manually. taking that into assumtion backtracking flags are only done for consecutive 1 to 1 point comparisons only. 

coordinate validation is done at ingestion only and points are rejected then and there. 
next a timestamp audit is run to check once for a rare occurance of timestmaps not being in order. again there is no reordering or mutation of gpx, just observing and flaggin unintentional variation.

the 3 graphs seen below are for studying the quality of gpx based on the only metrics that matter. timestamps validate a gpx big time since all comparisons can only validated via rate of what is possible. if no timestamps are available which is pretty rare these days, there is nothing to tell except if the sampling was done via consistent distance or consistnet time interval but just didnt log timestamps. having timestamps validate the activity itself and helps ascess the quality and trust that can be put on the data by comparing it to what is possible and likely.
the KDE (kernel density estimation) map all the delta that were calculated for the timestamps(if available) and coords. these are big indication to sampling rates, variability of sampling rate, change in sampling rate mid route, and much more. it all differs for different gpx's. a distance based logger will have a consistent high peak at or near one distance delta and that will indicate either distance sampling or consistent pace if time sampling can be seen in the time KDE. 
